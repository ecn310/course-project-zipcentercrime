------------------------------------------------------------
      name:  <unnamed>
       log:  C:\Users\sgortizh\OneDrive - Syracuse Universit
> y\EconResearch\course-project-zipcentercrime\Final Report\
> Reproducibility Package\Do files\Analysis_dofiles\FourRing
> Distances.log
  log type:  text
 opened on:  22 Apr 2025, 08:56:11

. 
. *** Then, import the Arc Data needed 
. 
. import delimited "ExtraFiles\2017_Arc_Data.csv"
(encoding automatically selected: UTF-8)
(2 vars, 620,359 obs)

.  
. *** Then, drop any values that were further than 2500 mete
> rs from any treatment center
. 
. drop if near_dist == -1
(205,143 observations deleted)

. 
. ssc install outreg2
checking outreg2 consistency and verifying not already insta
> lled...
all files already exist and are up to date.

. ssc install estout
checking estout consistency and verifying not already instal
> led...
all files already exist and are up to date.

. 
. *** Then, create the distance rings. This is the farther b
> ound of the distance ring
. 
. gen dist_group = 500 if near_dist <= 500
(354,168 missing values generated)

. replace dist_group = 1000 if (near_dist <= 1000 & near_dis
> t >500)
(105,456 real changes made)

. replace dist_group = 1500 if (near_dist <= 1500 & near_dis
> t >1000)
(117,642 real changes made)

. replace dist_group = 2000 if (near_dist <= 2000 & near_dis
> t >1500)
(78,555 real changes made)

. replace dist_group = 2500 if (near_dist <= 2500 & near_dis
> t >2000)
(52,515 real changes made)

. 
. *** Then, create the lower bound of the distance rings. 
. 
. gen dist_group2 = 0 if near_dist <= 500 
(354,168 missing values generated)

. replace dist_group2 = 500 if (near_dist <= 1000 & near_dis
> t >500)
(105,456 real changes made)

. replace dist_group2 = 1000 if (near_dist <= 1500 & near_di
> st >1000)
(117,642 real changes made)

. replace dist_group2 = 1500 if (near_dist <= 2000 & near_di
> st >1500)
(78,555 real changes made)

. replace dist_group2 = 2000 if (near_dist <= 2500 & near_di
> st >2000)
(52,515 real changes made)

. 
. 
. *dist_group2 of 2500 doesnt' have an uppderbound, so there
>  won't be anything
. *** At this point, every call has an assigned SATC, The di
> stance it is from that SATC, and a assigned upperbound dis
> tance ring and lowerbound distance ring. 
. ***Now, we count up the amount of observations per assigne
> d dist_group and identify that number. 
. 
. egen freq = count(near_dist), by(dist_group)

. 
. ***Then, we found the area for each respective group
. 
. gen area = (c(pi) * dist_group^2) - (c(pi) * dist_group2^2
> ) 

. 
. *** taking that difference in area and dividing the amount
>  of calls in that specific distance group by the new ring 
> of area will give us the number of calls per the increase 
> in area from one ring to the next largest, to standardize 
> the total calls by their repestive area sizes
. 
. gen CallxArea = freq / area

. 
. ***these commands create new seperate variables for each d
> istance group 
. gen dist_group_500 = 1 if near_dist <= 500
(354,168 missing values generated)

. gen dist_group_1000 = 1 if (near_dist <= 1000 & near_dist 
> >500)
(309,760 missing values generated)

. gen dist_group_1500 = 1 if (near_dist <= 1500 & near_dist 
> >1000)
(297,574 missing values generated)

. gen dist_group_2000 = 1 if (near_dist <= 2000 & near_dist 
> >1500)
(336,661 missing values generated)

. gen dist_group_2500 = 1 if (near_dist <= 2500 & near_dist 
> >2000)
(362,701 missing values generated)

. 
. 
. *** This is now total calls per ring. 
. ***This command collapses our data down, Using the various
>  variables we created for each seperate distance groups we
>  can now collapse the data by the count of how many of our
>  observations are within each individual distance groups p
> er SATC center
. 
. collapse (count) dist_group_500 dist_group_1000 dist_group
> _1500 dist_group_2000 dist_group_2500, by(near_fid)

. 
. *** When collapse (count), it reduced the number of total 
> calls to 35,731, when at the beginning there was 415,216 c
> alls. 
. 
. replace dist_group_500 = (dist_group_500 / 589048.6225) * 
> 1000000
variable dist_group_500 was long now double
(43 real changes made)

. replace dist_group_1000 = (dist_group_1000 / 1374446.786) 
> * 1000000
variable dist_group_1000 was long now double
(43 real changes made)

. replace dist_group_1500 = (dist_group_1500 / 2159844.949) 
> * 1000000
variable dist_group_1500 was long now double
(44 real changes made)

. replace dist_group_2000 = (dist_group_2000 / 2945243.113) 
> * 1000000
variable dist_group_2000 was long now double
(40 real changes made)

. replace dist_group_2500 = (dist_group_2500 / 3730641.276) 
> * 1000000
variable dist_group_2500 was long now double
(30 real changes made)

. 
. *** To check, add up the dist~500 column to see what total
>  calls come out
. 
. egen row_sum = rowtotal(dist_group_500 dist_group_1000 dis
> t_group_1500 dist_group_2000 dist_group_2500)

. summarize row_sum, meanonly

. display r(sum)
275580.73

. 
. 
. ***Couldn't we also collapse count by the CallxArea variab
> le? No, if we did, then we wouldn't be taking in SATCs int
> o the final analysis (in the unit) at all. We need to do m
> ean calls per ring per SATC center?
. ***So now, we have number of total 911 calls by ring for e
> ach SATC (1-44). How do we go about doing a two sample t-t
> est now? Either do a matrix, or this new thing I will try 
> out.
. 
. local vars dist_group_500 dist_group_1000 dist_group_1500 
> dist_group_2000 dist_group_2500

. 
. matrix Summary_Results_2 = J(1, 6, .)

. 
. *** Start the loop
. 
. foreach var of local vars {
  2.    
.    *** This is to summarize each variable 
.     summarize `var', detail
  3.     
.     *** This will save each of the needed summary stats fr
> om the Data
. 
.     local N = r(N)
  4.     local mean = r(mean)
  5.     local sd = r(sd)
  6.     local sum = r(sum)
  7.     local min = r(min)
  8.     local max = r(max)
  9.     
.         *** This adds the captured data into the Matrix
.     
.     matrix Summary_Results_2 = Summary_Results_2 \ (`N', `
> mean', `sd', `sum', `min', `max')
 10.         }

                   (count) dist_group_500
------------------------------------------------------------
> -
      Percentiles      Smallest
 1%            0              0
 5%     20.37183       15.27887
10%     101.8592       20.37183       Obs                  4
> 4
25%     1091.591       42.44132       Sum of wgt.          4
> 4

50%     1965.882                      Mean           2355.41
> 6
                        Largest       Std. dev.      2100.90
> 4
75%      3015.88       5654.881
90%     4312.038       7692.065       Variance        441379
> 8
95%     7692.065       7790.528       Skewness       1.67155
> 9
99%     9663.039       9663.039       Kurtosis       5.97668
> 5

                   (count) dist_group_1000
------------------------------------------------------------
> -
      Percentiles      Smallest
 1%            0              0
 5%     379.0616       205.1735
10%     508.5683       379.0616       Obs                  4
> 4
25%     881.4455       462.0041       Sum of wgt.          4
> 4

50%     1620.288                      Mean           1743.77
> 6
                        Largest       Std. dev.      1044.32
> 4
75%     2412.607       3325.702
90%     3071.781       3401.368       Variance        109061
> 3
95%     3401.368       3785.523       Skewness       .451749
> 9
99%     4324.649       4324.649       Kurtosis       2.44527
> 4

                   (count) dist_group_1500
------------------------------------------------------------
> -
      Percentiles      Smallest
 1%     .4629962       .4629962
 5%      36.1137       10.64891
10%     67.59744        36.1137       Obs                  4
> 4
25%      422.484       56.94853       Sum of wgt.          4
> 4

50%     1022.527                      Mean           1237.90
> 5
                        Largest       Std. dev.       1070.7
> 1
75%     1669.796       2950.212
90%     2501.568        3592.85       Variance        114642
> 0
95%      3592.85       3710.915       Skewness       1.36033
> 3
99%     4892.018       4892.018       Kurtosis       5.01165
> 1

                   (count) dist_group_2000
------------------------------------------------------------
> -
      Percentiles      Smallest
 1%            0              0
 5%            0              0
10%     .3395305              0       Obs                  4
> 4
25%      56.7016              0       Sum of wgt.          4
> 4

50%     462.1011                      Mean           606.177
> 8
                        Largest       Std. dev.      600.691
> 6
75%     974.6224       1722.778
90%     1618.542       1821.242       Variance       360830.
> 4
95%     1821.242       1863.344       Skewness       .844739
> 6
99%     2116.973       2116.973       Kurtosis       2.73134
> 8

                   (count) dist_group_2500
------------------------------------------------------------
> -
      Percentiles      Smallest
 1%            0              0
 5%            0              0
10%            0              0       Obs                  4
> 4
25%            0              0       Sum of wgt.          4
> 4

50%     193.1303                      Mean           319.924
> 3
                        Largest       Std. dev.      404.372
> 8
75%     405.8284       938.7126
90%     929.8669       1246.166       Variance       163517.
> 4
95%     1246.166       1263.054       Skewness       1.41964
> 6
99%     1567.827       1567.827       Kurtosis       4.16861
> 5

. 
.         *** Change column and row names
. matrix colnames Summary_Results_2 = "Obs" "Mean" "Std. dev
> ." "Sum" "Min" "Max"

. 
. *** Delete empty row from matrix
. 
. matrix Summary_Results_2 = Summary_Results_2[2..6, 1..cols
> of(Summary_Results_2)]

. 
. *** Rename the rows
. matrix rownames Summary_Results_2 = "500m" "1000m" "1500m"
>  "2000m" "2500m"

. 
. matrix list Summary_Results_2

Summary_Results_2[5,6]
             Obs       Mean  Std. dev.        Sum
 500m         44   2355.416  2100.9041   103638.3
1000m         44   1743.776   1044.324  76726.143
1500m         44  1237.9045  1070.7098  54467.799
2000m         44  606.17777  600.69157  26671.822
2500m         44  319.92428  404.37285  14076.668

             Min        Max
 500m          0  9663.0393
1000m          0  4324.6491
1500m   .4629962  4892.0178
2000m          0  2116.9729
2500m          0   1567.827

. 
. *** Export table
. esttab matrix(Summary_Results_2) using "Visual Graphics\Di
> st_4_Summary_Stats.tex", replace
(output written to Visual Graphics\Dist_4_Summary_Stats.tex)

. 
end of do-file

. do "C:\Users\sgortizh\AppData\Local\Temp\STD265c_000000.tm
> p"

. matrix t_tests = J(4, 4, .)  // 4 comparisons, 4 columns (
> Mean 1, Mean 2, Difference, p_value)

. 
. * Run the first t-test: dist_group_500 vs. dist_group_1000
. ttest dist_group_500 == dist_group_1000

Paired t test
------------------------------------------------------------
> ------------------
Variable |     Obs        Mean    Std. err.   Std. dev.   [9
> 5% conf. interval]
---------+--------------------------------------------------
> ------------------
dis~_500 |      44    2355.416    316.7232    2100.904    17
> 16.683                                                    
>           2994.149
dis~1000 |      44    1743.776    157.4378    1044.324    14
> 26.272                                                    
>           2061.279
---------+--------------------------------------------------
> ------------------
    diff |      44      611.64     243.448    1614.851    12
> 0.6804                                                    
>             1102.6
------------------------------------------------------------
> ------------------
     mean(diff) = mean(dist_group_500 - dist_group_1000)    
>       t =   2.5124
 H0: mean(diff) = 0                              Degrees of 
> freedom =       43

 Ha: mean(diff) < 0           Ha: mean(diff) != 0           
> Ha: mean(diff) > 0
 Pr(T < t) = 0.9921         Pr(|T| > |t|) = 0.0158          
> Pr(T > t) = 0.0079

. matrix t_tests[1, 1] = r(mu_1)   // Mean of dist_group_250

. matrix t_tests[1, 2] = r(mu_2)   // Mean of dist_group_500

. matrix t_tests[1, 3] = r(mu_1) - r(mu_2)  // Difference of
>  means

. matrix t_tests[1, 4] = r(p)     // p-value

. 
. * Run the second t-test: dist_group_1000 vs. dist_group_15
> 00
. ttest dist_group_1000 == dist_group_1500

Paired t test
------------------------------------------------------------
> ------------------
Variable |     Obs        Mean    Std. err.   Std. dev.   [9
> 5% conf. interval]
---------+--------------------------------------------------
> ------------------
dis~1000 |      44    1743.776    157.4378    1044.324    14
> 26.272                                                    
>           2061.279
dis~1500 |      44    1237.905    161.4156     1070.71     9
> 12.379                                                    
>            1563.43
---------+--------------------------------------------------
> ------------------
    diff |      44    505.8714    95.14813    631.1413     3
> 13.987                                                    
>           697.7559
------------------------------------------------------------
> ------------------
     mean(diff) = mean(dist_group_1000 - dist_group_1500)   
>       t =   5.3167
 H0: mean(diff) = 0                              Degrees of 
> freedom =       43

 Ha: mean(diff) < 0           Ha: mean(diff) != 0           
> Ha: mean(diff) > 0
 Pr(T < t) = 1.0000         Pr(|T| > |t|) = 0.0000          
> Pr(T > t) = 0.0000

. matrix t_tests[2, 1] = r(mu_1)   // Mean of dist_group_500

. matrix t_tests[2, 2] = r(mu_2)   // Mean of dist_group_750

. matrix t_tests[2, 3] = r(mu_1) - r(mu_2)  // Difference of
>  means

. matrix t_tests[2, 4] = r(p)     // p-value

. 
. * Run the third t-test: dist_group_1500 vs. dist_group_200
> 0
. ttest dist_group_1500 == dist_group_2000

Paired t test
------------------------------------------------------------
> ------------------
Variable |     Obs        Mean    Std. err.   Std. dev.   [9
> 5% conf. interval]
---------+--------------------------------------------------
> ------------------
dis~1500 |      44    1237.905    161.4156     1070.71     9
> 12.379                                                    
>            1563.43
dis~2000 |      44    606.1778    90.55766    600.6916    42
> 3.5508                                                    
>           788.8047
---------+--------------------------------------------------
> ------------------
    diff |      44    631.7267    140.9594    935.0186    34
> 7.4551                                                    
>           915.9984
------------------------------------------------------------
> ------------------
     mean(diff) = mean(dist_group_1500 - dist_group_2000)   
>       t =   4.4816
 H0: mean(diff) = 0                              Degrees of 
> freedom =       43

 Ha: mean(diff) < 0           Ha: mean(diff) != 0           
> Ha: mean(diff) > 0
 Pr(T < t) = 1.0000         Pr(|T| > |t|) = 0.0001          
> Pr(T > t) = 0.0000

. matrix t_tests[3, 1] = r(mu_1)   // Mean of dist_group_750

. matrix t_tests[3, 2] = r(mu_2)   // Mean of dist_group_100
> 0

. matrix t_tests[3, 3] = r(mu_1) - r(mu_2)  // Difference of
>  means

. matrix t_tests[3, 4] = r(p)     // p-value

. 
. * Run the fourth t-test: dist_group_1000 vs. dist_group_12
> 50
. ttest dist_group_2000 == dist_group_2500

Paired t test
------------------------------------------------------------
> ------------------
Variable |     Obs        Mean    Std. err.   Std. dev.   [9
> 5% conf. interval]
---------+--------------------------------------------------
> ------------------
dis~2000 |      44    606.1778    90.55766    600.6916    42
> 3.5508                                                    
>           788.8047
dis~2500 |      44    319.9243     60.9615    404.3728    19
> 6.9837                                                    
>           442.8649
---------+--------------------------------------------------
> ------------------
    diff |      44    286.2535    56.54425    375.0721    17
> 2.2211                                                    
>           400.2858
------------------------------------------------------------
> ------------------
     mean(diff) = mean(dist_group_2000 - dist_group_2500)   
>       t =   5.0625
 H0: mean(diff) = 0                              Degrees of 
> freedom =       43

 Ha: mean(diff) < 0           Ha: mean(diff) != 0           
> Ha: mean(diff) > 0
 Pr(T < t) = 1.0000         Pr(|T| > |t|) = 0.0000          
> Pr(T > t) = 0.0000

. matrix t_tests[4, 1] = r(mu_1)   // Mean of dist_group_100
> 0

. matrix t_tests[4, 2] = r(mu_2)   // Mean of dist_group_125
> 0

. matrix t_tests[4, 3] = r(mu_1) - r(mu_2)  // Difference of
>  means

. matrix t_tests[4, 4] = r(p)     // p-value

. 
. * Now, name the rows and columns for the one-sample t-test
>  table 
. matrix colnames t_tests = "Lower Ring Mean" "Upper Ring Me
> an" "Mean Difference" "P-Value"

. matrix rownames t_tests = "500m-1000m" "1000m-1500m" "1500
> m-2000m" "2000m-2500m"

. 
. * Now, craete the tex file we will put the t-tests in 
. file open t_tests_four using "4_t_tests_results.tex", writ
> e replace

. file write t_tests_four "\begin{table}[htbp]" _n

. file write t_tests_four "\centering" _n

. file write t_tests_four "\begin{tabular}{l|c c c c}" _n

. file write t_tests_four "\hline" _n

. file write t_tests_four "Comparison & Mean 1 & Mean 2 & Di
> fference & P-value \\" _n

. file write t_tests_four "\hline" _n

. 
. *Now, create the local rownames for the table
. local rownames 500m-1000m 1000m-1500m 1500m-2000m 2000m-25
> 00m

. local i = 1

. foreach row of local rownames {
  2.         local mean1 = string(el(t_tests, `i', 1), "%9.1
> f")
  3.         local mean2 = string(el(t_tests, `i', 2), "%9.1
> f")
  4.         local diff  = string(el(t_tests, `i', 3), "%9.1
> f")
  5.         local pval  = string(el(t_tests, `i', 4), "%9.3
> f")
  6.         file write t_tests_file "`row' & `mean1' & `mea
> n2' & `diff' & `pval' \\" _n
  7.         local i = `i' + 1
  8. }
file handle t_tests_file not found
r(111);

end of do-file

r(111);

. do "C:\Users\sgortizh\AppData\Local\Temp\STD265c_000000.tm
> p"

. foreach row of local rownames {
  2.         local mean1 = string(el(t_tests, `i', 1), "%9.1
> f")
  3.         local mean2 = string(el(t_tests, `i', 2), "%9.1
> f")
  4.         local diff  = string(el(t_tests, `i', 3), "%9.1
> f")
  5.         local pval  = string(el(t_tests, `i', 4), "%9.3
> f")
  6.         file write t_tests_four "`row' & `mean1' & `mea
> n2' & `diff' & `pval' \\" _n
  7.         local i = `i' + 1
  8. }

. 
. file write t_tests_four "\hline" _n

. file write t_tests_four "\end{tabular}" _n

. file write t_tests_four "\caption{\textbf{One-sample T-tes
> t Results by Distance Rings}}" _n

. file write t_tests_four "\label{tab:ttests}" _n

. file write t_tests_four "\end{table}" _n

. file close t_tests_four

.  
.  * Check the matrix
.  matrix list t_tests

t_tests[4,4]
             Lower Ring~n  Upper Ring~n  Mean Diffe~e
 500m-1000m      2355.416      1743.776     611.64003
1000m-1500m      1743.776     1237.9045     505.87145
1500m-2000m     1237.9045     606.17777     631.72674
2000m-2500m     606.17777     319.92428     286.25349

                  P-Value
 500m-1000m     .01582287
1000m-1500m     3.567e-06
1500m-2000m     .00005416
2000m-2500m     8.248e-06

. 
. 
end of do-file

. do "C:\Users\sgortizh\AppData\Local\Temp\STD265c_000000.tm
> p"

. matrix drop _all

. 
. **** Create two new matrices for storing Confidence Interv
> al data
. 
. matrix lci = J(5, 1, .) 

. matrix uci = J(5, 1, .)  

. 
. *** List of variables to be groupped for looping
. 
. local groups dist_group_500 dist_group_1000 dist_group_150
> 0 dist_group_2000 dist_group_2500 

. 
. *** Begin loop by telling Stata which row to begin at
. 
. local row_index = 1

. foreach var of local groups {
  2.    *** Calculate basic statistics
.    summarize `var', detail
  3.    
.    *** Mean of the variable
.    local mean = r(mean)
  4.    
.    *** Standard deviation of the variable
.    local sd = r(sd)
  5.    
.    *** Number of observations
.    local n = r(N)
  6.    
.    *** Degrees of freedom
.    local df = `n' - 1
  7.    
.    *** Calculate standard error
.    local se = `sd' / sqrt(`n')
  8.    
.    *** Calculate t-critical value
.    scalar t_crit = invttail(`df', 0.05)
  9.    
.    *** Calculate confidence interval
.    local ci_lower = `mean' - (t_crit * `se')
 10.    local ci_upper = `mean' + (t_crit * `se')
 11.    
.    *** Display Data to check if correct
.    display "Variable: `var'"
 12.    display "Mean: `mean'"
 13.    display "Standard Deviation: `sd'"
 14.    display "Number of Observations: `n'"
 15.    display "Degrees of Freedom: `df'"
 16.    display "Standard Error: `se'"
 17.    display "CI Lower: `ci_lower'"
 18.    display "CI Upper: `ci_upper'"
 19.    
.    *** Store in matrices
.    matrix lci[`row_index',1] = `ci_lower'
 20.    matrix uci[`row_index',1] = `ci_upper'
 21.    
.    *** Increment row index
.    local row_index = `row_index' + 1
 22. }

                   (count) dist_group_500
------------------------------------------------------------
> -
      Percentiles      Smallest
 1%            0              0
 5%     20.37183       15.27887
10%     101.8592       20.37183       Obs                  4
> 4
25%     1091.591       42.44132       Sum of wgt.          4
> 4

50%     1965.882                      Mean           2355.41
> 6
                        Largest       Std. dev.      2100.90
> 4
75%      3015.88       5654.881
90%     4312.038       7692.065       Variance        441379
> 8
95%     7692.065       7790.528       Skewness       1.67155
> 9
99%     9663.039       9663.039       Kurtosis       5.97668
> 5
Variable: dist_group_500
Mean: 2355.415991919318
Standard Deviation: 2100.904112229803
Number of Observations: 44
Degrees of Freedom: 43
Standard Error: 316.7232118536804
CI Lower: 1822.981879447891
CI Upper: 2887.850104390745

                   (count) dist_group_1000
------------------------------------------------------------
> -
      Percentiles      Smallest
 1%            0              0
 5%     379.0616       205.1735
10%     508.5683       379.0616       Obs                  4
> 4
25%     881.4455       462.0041       Sum of wgt.          4
> 4

50%     1620.288                      Mean           1743.77
> 6
                        Largest       Std. dev.      1044.32
> 4
75%     2412.607       3325.702
90%     3071.781       3401.368       Variance        109061
> 3
95%     3401.368       3785.523       Skewness       .451749
> 9
99%     4324.649       4324.649       Kurtosis       2.44527
> 4
Variable: dist_group_1000
Mean: 1743.775966548968
Standard Deviation: 1044.324011732172
Number of Observations: 44
Degrees of Freedom: 43
Standard Error: 157.4377684761057
CI Lower: 1479.111946386205
CI Upper: 2008.439986711731

                   (count) dist_group_1500
------------------------------------------------------------
> -
      Percentiles      Smallest
 1%     .4629962       .4629962
 5%      36.1137       10.64891
10%     67.59744        36.1137       Obs                  4
> 4
25%      422.484       56.94853       Sum of wgt.          4
> 4

50%     1022.527                      Mean           1237.90
> 5
                        Largest       Std. dev.       1070.7
> 1
75%     1669.796       2950.212
90%     2501.568        3592.85       Variance        114642
> 0
95%      3592.85       3710.915       Skewness       1.36033
> 3
99%     4892.018       4892.018       Kurtosis       5.01165
> 1
Variable: dist_group_1500
Mean: 1237.904516905124
Standard Deviation: 1070.709822055857
Number of Observations: 44
Degrees of Freedom: 43
Standard Error: 161.4155790503397
CI Lower: 966.5535159231274
CI Upper: 1509.255517887121

                   (count) dist_group_2000
------------------------------------------------------------
> -
      Percentiles      Smallest
 1%            0              0
 5%            0              0
10%     .3395305              0       Obs                  4
> 4
25%      56.7016              0       Sum of wgt.          4
> 4

50%     462.1011                      Mean           606.177
> 8
                        Largest       Std. dev.      600.691
> 6
75%     974.6224       1722.778
90%     1618.542       1821.242       Variance       360830.
> 4
95%     1821.242       1863.344       Skewness       .844739
> 6
99%     2116.973       2116.973       Kurtosis       2.73134
> 8
Variable: dist_group_2000
Mean: 606.1777722900355
Standard Deviation: 600.6915724808473
Number of Observations: 44
Degrees of Freedom: 43
Standard Error: 90.55766184761571
CI Lower: 453.9439400074881
CI Upper: 758.4116045725829

                   (count) dist_group_2500
------------------------------------------------------------
> -
      Percentiles      Smallest
 1%            0              0
 5%            0              0
10%            0              0       Obs                  4
> 4
25%            0              0       Sum of wgt.          4
> 4

50%     193.1303                      Mean           319.924
> 3
                        Largest       Std. dev.      404.372
> 8
75%     405.8284       938.7126
90%     929.8669       1246.166       Variance       163517.
> 4
95%     1246.166       1263.054       Skewness       1.41964
> 6
99%     1567.827       1567.827       Kurtosis       4.16861
> 5
Variable: dist_group_2500
Mean: 319.924280833676
Standard Deviation: 404.3728479234513
Number of Observations: 44
Degrees of Freedom: 43
Standard Error: 60.96150054406966
CI Lower: 217.443688245776
CI Upper: 422.404873421576

. 
. *** Display final matrices to check if correct
. 
. matrix list lci

lci[5,1]
           c1
r1  1822.9819
r2  1479.1119
r3  966.55352
r4  453.94394
r5  217.44369

. matrix list uci

uci[5,1]
           c1
r1  2887.8501
r2    2008.44
r3  1509.2555
r4   758.4116
r5  422.40487

. 
. *** Reshape the data to be over distance instead of treatm
> ent center  - what was this purpose?
. 
. reshape long dist_group_, i(near_fid) j(Distance)
(j = 500 1000 1500 2000 2500)

Data                               Wide   ->   Long
------------------------------------------------------------
> -----------------
Number of observations               44   ->   220         
Number of variables                   7   ->   4           
j variable (5 values)                     ->   Distance
xij variables:
dist_group_500 dist_group_1000 ... dist_group_2500->dist_gro
> up_
------------------------------------------------------------
> -----------------

. 
. *** Collapse the data to be the mean number of calls at ea
> ch distance
. 
. collapse (mean) dist_group_, by(Distance)

. 
. rename dist_group mean

. 
. *** Turn the two matrices into seperate variables 
. 
. svmat lci, names(lci)

. svmat uci, names(uci)

. 
. rename mean Mean 

. 
. *** Plot the graph
. graph twoway (bar Mean Distance, lwidth(02) color(navy)) (
> rcap lci1 uci1 Distance, lcolor(black) lwidth(thin)), ytit
> le("Mean Calls per Km²", angle(horizontal))  xtitle("Dista
> nce Groups (m)", size(medsmall))  legend(label (1 "Mean Ca
> lls per Km^2") label(2 "95% Confidence Intervals")) graphr
> egion(color(white)) title("Mean Calls by Distance Group wi
> th 95% CIs", size(medium))

. 
. *** Export Graph
. graph export "Visual Graphics\2CI_Graph.png", replace name
> (MyGraph)
could not find Graph window
r(693);

end of do-file

r(693);

